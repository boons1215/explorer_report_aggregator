# Source: https://github.com/boons1215/explorer_report_aggregator
from datetime import date
from numpy import nan 
from os import stat
from sys import argv
from base64 import b64decode
from io import StringIO, BytesIO
from dash.dependencies import Input, Output, State
import pandas as pd
import dash, dash_table, argparse
import dash_html_components as html
import dash_core_components as dcc
import plotly.express as px


def csv_formatter(df):
    # update the column name to all lower cap and without space
    df.columns = df.columns.str.replace(' ', '_')
    df.columns = df.columns.str.lower()
   
    # fill value if the column is empty
    df.fillna({'consumer_role': 'NO_LABEL', 'consumer_app': 'NO_LABEL', 'consumer_env': 'NO_LABEL', 'consumer_loc': 'NO_LABEL'}, inplace=True)
    df.fillna({'provider_role': 'NO-LABEL', 'provider_app': 'NO_LABEL', 'provider_env': 'NO_LABEL', 'provider_loc': 'NO_LABEL'}, inplace=True)

    # rename the column since we only track the subnet instead of IP
    df.rename(columns={'consumer_ip': 'consumer_subnet', 'provider_ip': 'provider_subnet'}, inplace=True)

    return df

def combine_aggroup_column(df):
    # create new columns to combine appgroup with location
    df['consumer_appgroup_combined'] = df['consumer_role'] + " | " + df['consumer_app'] + " | " + df['consumer_env'] + " | " + df['consumer_loc']
    df['provider_appgroup_combined'] = df['provider_role'] + " | " + df['provider_app'] + " | " + df['provider_env'] + " | " + df['provider_loc']
    
    # replace the column if 4 tuples are NO_LABEL, it means it is a IPList
    NO_LABEL = ['NO_LABEL | NO_LABEL | NO_LABEL | NO_LABEL']
    df['consumer_appgroup_combined'].replace(NO_LABEL, nan, regex=True, inplace=True)
    df['provider_appgroup_combined'].replace(NO_LABEL, nan, regex=True, inplace=True)

    # in 21.2, the report which generated by the database directly, not include the "Draft Policy Decision" column
    # the report which include the column must be generated under the draft policy view.    
    # 0 is system, 1 is draft, default is 1
    # in 21.2, there is backend report which not having draft policy decision column and report upto 200k
    # Explorer gernerated report has draft policy and only upto 100k
    # in 21.3, there is an additional column named "Consumer FQDN"
    system_or_draft = 1
    if "consumer_subnet" in list(df.columns.values) and "reported_policy_decision" in list(df.columns.values) and "draft_policy_decision" not in list(df.columns.values):
        print("\nNOTE: The imported report is returned from the database directly in PCE 21.2.")
        print("\"Draft Policy Decision\" column is not included.")
        print("If you need this column, generate the report again in the \"Draft Policy\" Explorer view.\n")
        system_or_draft = 0

    return df, system_or_draft

def determine_iplist_or_vens_rows(df, system_or_draft):
    # backup updated raw csv file
    df.to_csv(path + "updated_raw_" + datestr + ".csv", index=False)
    # if either one column below is NaN, identify the row has iplist
    df_src_iplist = df.loc[(df['consumer_appgroup_combined'].isna()) & (df['consumer_iplist'].notna())]
    df_dst_iplist = df.loc[(df['provider_iplist'].notna()) & (df['provider_appgroup_combined'].isna())]

    if system_or_draft == 0:
        # sanitize the output for consumer iplist rows
        # sample cols: ['transmission', 'port', 'protocol', 'reported_policy_decision', 'reported_by', 'first_detected', 'last_detected', 'num_flows']
        df_src_iplist_result = df_src_iplist[SRC_IPL_COLS + common_cols].copy()
        # sanitize the output for provider iplist rows
        df_dst_iplist_result = df_dst_iplist[DST_IPL_COLS + common_cols].copy()
    else:
        common_cols.insert(4, 'draft_policy_decision')
        # sample cols: ['transmission', 'port', 'protocol', 'reported_policy_decision', 'draft_policy_decision', 'reported_by', 'first_detected', 'last_detected', 'num_flows']
        # sanitize the output for consumer iplist rows, include draft_policy_decision column
        df_src_iplist_result = df_src_iplist[SRC_IPL_COLS + common_cols].copy()
        # sanitize the output for provider iplist rows
        df_dst_iplist_result = df_dst_iplist[DST_IPL_COLS + common_cols].copy()

    # if either one column below is not NaN, identify the row is not contain iplist. both sides are VENs.
    df_both_vens_result = df.loc[(df['consumer_appgroup_combined'].notna()) & (df['provider_appgroup_combined'].notna())]

    # return both VENs fall under intrascope
    df_both_vens_intrascope_result = df.loc[(df['consumer_appgroup_combined']) == (df['provider_appgroup_combined'])]

    # return both VENs fall under extrascope
    df_both_vens_extrascope_result = df.loc[(df['consumer_appgroup_combined']) != (df['provider_appgroup_combined'])]

    return df_src_iplist_result, df_dst_iplist_result, df_both_vens_result, df_both_vens_intrascope_result, df_both_vens_extrascope_result

def consumer_as_iplist_result(df_src_iplist_result):
    # trim the last octet of IP address for better aggregate and dedup as subnet format instead of IP for consumer as iplist
    df_src_iplist_result['consumer_subnet'] = df_src_iplist_result['consumer_subnet'].str.replace(r'\.\d+$', '.0', regex=True)

    cols = SRC_IPL_COLS + common_cols[:-3]
    number_of_sort = len(cols) * ["True"]

    # sorting
    df_src_iplist_result.sort_values(cols, ascending=number_of_sort, inplace=True)
    # aggregate the common flows then list the first detected and last detected with a sum of num of flows

    df_src_iplist_result = df_src_iplist_result.groupby(cols, axis=0, as_index=True).agg(first_detected=('first_detected', min), last_detected=('last_detected', max), num_flows=('num_flows', sum))

    return df_src_iplist_result

def provider_as_iplist_result(df_dst_iplist_result):
    # trim the last octet of IP address for better aggregate and dedup as subnet format instead of IP for provider as iplist
    df_dst_iplist_result['provider_subnet'] = df_dst_iplist_result['provider_subnet'].str.replace(r'\.\d+$', '.0', regex=True)

    cols = DST_IPL_COLS + common_cols[:-3]
    number_of_sort = len(cols) * ["True"]

    # sorting
    df_dst_iplist_result.sort_values(cols, ascending=number_of_sort, inplace=True)
    # aggregate the common flows then list the first detected and last detected with a sum of num of flows
    df_dst_iplist_result = df_dst_iplist_result.groupby(cols, axis=0, as_index=True).agg(first_detected=('first_detected', min), last_detected=('last_detected', max), num_flows=('num_flows', sum))

    return df_dst_iplist_result

def both_vens_result(df_both_vens):
    # sanitize the output for both sides are VENs
    df_both_vens_result = df_both_vens.copy()

    cols = DST_IPL_COLS[0:4] + SRC_IPL_COLS[2:3] + SRC_IPL_COLS[3::] + common_cols[:-3]
    number_of_sort = len(cols) * ["True"]

    # sorting
    df_both_vens_result.sort_values(cols, ascending=number_of_sort, inplace=True)
    # aggregate the common flows then list the first detected and last detected with a sum of num of flows
    df_both_vens_result = df_both_vens_result.groupby(cols, axis=0, as_index=True).agg(first_detected=('first_detected', min), last_detected=('last_detected', max), num_flows=('num_flows', sum))

    return df_both_vens_result

def reports_output(consumer_iplist_report, provider_iplist_report, intrascope_report, extrascope_report):
    df_dict = {
        "consumer_iplist_agg_report": consumer_iplist_report,
        "provider_iplist_agg_report": provider_iplist_report,
        "intrascope_agg_report": intrascope_report,
        "extrascope_agg_report": extrascope_report
    }

    for key, value in df_dict.items():
        x = '{}'.format(key)
        value.to_csv(path + x + datestr + ".csv")

def parse_contents(contents, filename):
    # Parse the imported csv file contents, styling
    content_type, content_string = contents.split(',')

    decoded = b64decode(content_string)
    try:
        if 'csv' in filename:
            # Assume that the user uploaded a CSV file
            df = pd.read_csv(
                StringIO(decoded.decode('utf-8')))
        elif 'xls' in filename:
            # Assume that the user uploaded an excel file
            df = pd.read_excel(BytesIO(decoded))
    except Exception as e:
        print(e)
        return html.Div([
            'There was an error processing this file.'
        ])

    return html.Div([
        html.H5("Filename: " + filename, style={'color': '#DFDEDF', 'font-family' : '-apple-system, BlinkMacSystemFont, sans-serif', 'fontSize': 16, 'fontWeight': 'bold'}),
        html.Br(),
        html.Br(),

        dash_table.DataTable(           # toggle column button
            id='datatable-interactivity',
            columns=[
                {"name": i, "id": i, "deletable": True, "selectable": True}
                if i == "id"
                else {"name": i, "id": i, "deletable": True, "selectable": True, "hideable": True}
                for i in df.columns
            ],
            export_format="csv",        # export button
            css =[
                {   # toggle column button style
                    'selector':'.show-hide, .export, .show-hide-menu-item',
                    'rule':'font-family:-apple-system, BlinkMacSystemFont, sans-serif; color:#DFDEDF; background:#6E6D70; cursor: pointer; touch-action: manipulation; border: none; border-radius: 6px;',
                }, #change font
            ],
            data=df.to_dict('records'),  # the contents of the table
            editable=True,              # allow editing of data inside all cells
            filter_action="native",     # allow filtering of data by user ('native') or not ('none')
            sort_action="native",       # enables data to be sorted per-column by user or not ('none')
            sort_mode="multi",          # sort across 'multi' or 'single' columns
            column_selectable="multi",  # allow users to select 'multi' or 'single' columns
            row_selectable="multi",     # allow users to select 'multi' or 'single' rows
            row_deletable=True,         # choose if user can delete a row (True) or not (False)
            selected_columns=[],        # ids of columns that user selects
            selected_rows=[],           # indices of rows that user selects
            page_action="native",       # all data is passed to the table up-front or not ('none')
            page_current=0,             # page number that user is on
            page_size=25,               # number of rows visible per page
            style_filter={
                'backgroundColor': '#6ead52',
                'border': '1px solid black'
            },
            style_cell={                # ensure adequate header width when text is shorter than cell's text
                'backgroundColor': '#000000',
                'overflowX': 'auto',
                'minWidth': '160px', 
                'width': '380px',
                'textAlign': 'center'
            },
            style_cell_conditional=(
                [    # align text columns to left. By default they are aligned to right
                    {
                        'if': {'column_id': c},
                        'textAlign': 'right',
                        'minWidth': '380px'
                    } for c in ['consumer_appgroup_combined', 'provider_appgroup_combined']
                ] + 
                [    # align text columns to left. By default they are aligned to right
                    {
                        'if': {'column_id': c},
                        'textAlign': 'right',
                        'minWidth': '200px'
                    } for c in ['provider_iplist', 'consumer_iplist', 'consumer_subnet', 'provider_subnet', 'consumer_iplist']
                ] + 
                [    # align text columns to center
                    {
                        'if': {'column_id': c},
                        'textAlign': 'left',
                        'minWidth': '255px'
                    } for c in ['reported_policy_decision', 'draft_policy_decision']
                ] +
                [    # align text columns to center
                    {
                        'if': {'column_id': c},
                        'textAlign': 'right',
                        'minWidth': '130px'
                    } for c in ['num_flows', 'port', 'id']
                ] 
            ),
            style_header={ 
                'border': '1px solid black',
                'color': '#ffffff',
                'fontWeight': 'bold',
            },
            style_data={                # overflow cells' content into multiple lines
                'whiteSpace': 'normal',
                'height': 'auto',
                'border': '0.5px solid black',
                'color': '#6db432'
            },
            style_data_conditional=(
                [
                    {   # identify the reported policy decision, "Potentially Blocked" is orange                
                        'if': {
                            'filter_query': '{reported_policy_decision} = "Potentially Blocked"', 
                        },
                        'color': '#e4a91b'
                    }, 
                    {   # identify the reported policy decision, "Blocked" is red      
                        'if': {
                            'filter_query': '{reported_policy_decision} = "Blocked"', 
                        },
                        'color': '#dd475a'
                    },
                    {   # identify the reported policy decision, "Unknown" is grey      
                        'if': {
                            'filter_query': '{reported_policy_decision} = "Unknown"', 
                        },
                        'color': '#a8a8a8'
                    },
                    {   # identify the draft policy decision, "Blocked" is red      
                        'if': {
                            'filter_query': '{draft_policy_decision} = "Blocked"', 
                            'column_id': 'draft_policy_decision'
                        },
                        'color': '#dd475a'
                    },
                    {   # identify the draft policy decision, "Blocked" is red      
                        'if': {
                            'filter_query': '{draft_policy_decision} = "Allowed"', 
                            'column_id': 'draft_policy_decision'
                        },
                        'color': '#6db432'
                    },
                ]
            )
        ),

        html.Br(),
        html.Br(),
        html.Div(id='output-data-upload'),
        html.Div(id='bar-container')
    ])

def upload_function():
    # Upload function for dash table
    app.layout = html.Div([
        dcc.Upload(
            id='upload-data',
            children=html.Div([
                'Drag and Drop or ',
                html.A('Select Files'),
                html.Br(),
                'Refresh page before uploading a CSV'
            ]),
            style={
                'width': '100%',
                'height': '60px',
                'lineHeight': '60px',
                'borderWidth': '1px',
                'borderStyle': 'dashed',
                'borderRadius': '5px',
                'textAlign': 'center',
                'margin': '10px', 
                'font-family': '-apple-system, BlinkMacSystemFont, sans-serif',
                'color' :'#DFDEDF',
                'fontWeight': 'bold'
            },
            # Allow multiple files to be uploaded
            multiple=True
        ),
        html.Div(id='output-data-upload'),
    ])

    return app.layout

def dash_table_output(app_layout):
    # Dash-table call the table output to parse_contents function
    @app.callback(Output('output-data-upload', 'children'),
                Input('upload-data', 'contents'),
                State('upload-data', 'filename'))
    def update_output(list_of_contents, list_of_names):
        if list_of_contents is not None:
            children = [
                parse_contents(c, n) for c, n in
                zip(list_of_contents, list_of_names)]
            return children

def bar_chart_output(table_layout):
    # Create bar chart
    @app.callback(
        Output(component_id='bar-container', component_property='children'),
        [Input(component_id='datatable-interactivity', component_property="derived_virtual_data"),
        Input(component_id='datatable-interactivity', component_property='derived_virtual_selected_rows'),
        Input(component_id='datatable-interactivity', component_property='derived_virtual_selected_row_ids'),
        Input(component_id='datatable-interactivity', component_property='selected_rows'),
        Input(component_id='datatable-interactivity', component_property='derived_virtual_indices'),
        Input(component_id='datatable-interactivity', component_property='derived_virtual_row_ids'),
        Input(component_id='datatable-interactivity', component_property='active_cell'),
        Input(component_id='datatable-interactivity', component_property='selected_cells'),
        Input(component_id='datatable-interactivity', component_property='selected_row_ids')]
    )
    def update_bar(all_rows_data, slctd_row_indices, slct_rows_names, slctd_rows,
                order_of_rows_indices, order_of_rows_names, actv_cell, slctd_cell, selected_row_ids):
        print('***************************************************************************')
        print('Data across all pages pre or post filtering: {}'.format(all_rows_data))
        print('---------------------------------------------')
        print("Indices of selected rows if part of table after filtering:{}".format(slctd_row_indices))
        print("Names of selected rows if part of table after filtering: {}".format(slct_rows_names))
        print("Indices of selected rows regardless of filtering results: {}".format(slctd_rows))
        print('---------------------------------------------')
        print("Indices of all rows pre or post filtering: {}".format(order_of_rows_indices))
        print("Names of all rows pre or post filtering: {}".format(order_of_rows_names))
        print("---------------------------------------------")
        print("Complete data of active cell: {}".format(actv_cell))
        print("Complete data of all selected cells: {}".format(slctd_cell))
        print('Total number of rows after post filtering: {}'.format(len(all_rows_data)))
        print('---------------------------------------------')

        dff = pd.DataFrame(all_rows_data)
        # Ref: https://github.com/Coding-with-Adam/Dash-by-Plotly/blob/master/DataTable/datatable_intro_and_sort.py
        # highlight the color when select the row and click the column
        # selected_id_set = set(selected_row_ids or [])
        # active_row_id = actv_cell['row_id'] if actv_cell else None
        # colors = ['#FF69B4' if id == active_row_id  
        #           else '#45cbff' if id in selected_id_set
        #           else '#0a075d'
        #           for id in range(len(dff))]

        # for intrascope and extrascope dataframe
        if "consumer_appgroup_combined" in dff and "provider_appgroup_combined" in dff and "num_flows" in dff:
            return [
                dcc.Graph(id='bar-chart',
                            figure=px.bar(
                                data_frame=dff,
                                x='num_flows',
                                y="consumer_appgroup_combined",
                                color="reported_policy_decision",
                                color_discrete_map={
                                    'Allowed': '#508104',
                                    'Blocked': '#b64201',
                                    'Potentially Blocked': '#db8200',
                                    'Unknown': '#4a4a4a'
                                },
                                barmode="stack",
                                height=700,
                                labels={"num_flows": "Number of Flows based on Provider App Groups"}
                            ).update_layout(showlegend=True, xaxis={'categoryorder': 'total ascending'}, paper_bgcolor="#1c2841", plot_bgcolor="#1c2841", newshape_line_width=1, font_family='Open Sans, sans-serif', font_color='#FFFFFF')
                            .update_traces(hovertemplate="<b>%{x}</b><extra></extra>")
                        )
            ]
        
        # for consumer is iplist dataframe
        if "consumer_iplist" in dff and "num_flows" in dff:
            return [
                dcc.Graph(id='bar-chart',
                            figure=px.bar(
                                data_frame=dff,
                                x='num_flows',
                                y="consumer_iplist",
                                color="reported_policy_decision",
                                color_discrete_map={
                                    'Allowed': '#508104',
                                    'Blocked': '#b64201',
                                    'Potentially Blocked': '#db8200',
                                    'Unknown': '#4a4a4a'
                                },
                                barmode="stack",
                                height=700,
                                labels={"num_flows": "Number of Flows based on Provider App Groups"}
                            ).update_layout(showlegend=True, xaxis={'categoryorder': 'total ascending'}, paper_bgcolor="#1c2841", plot_bgcolor="#1c2841", newshape_line_width=1, font_family='Open Sans, sans-serif', font_color='#FFFFFF')
                            .update_traces(hovertemplate="<b>%{x}</b><extra></extra>")
                        )
            ]

        # for provider is iplist dataframe
        if "provider_iplist" in dff and "num_flows" in dff:
            return [
                dcc.Graph(id='bar-chart',
                            figure=px.bar(
                                data_frame=dff,
                                x='num_flows',
                                y="provider_iplist",
                                color="reported_policy_decision",
                                color_discrete_map={
                                    'Allowed': '#508104',
                                    'Blocked': '#b64201',
                                    'Potentially Blocked': '#db8200',
                                    'Unknown': '#4a4a4a'
                                },
                                barmode="stack",
                                height=700,
                                labels={"num_flows": "Number of Flows based on Consumer App Groups"}
                            ).update_layout(showlegend=True, xaxis={'categoryorder': 'total ascending'}, paper_bgcolor="#242a44", plot_bgcolor="#242a44", newshape_line_width=4, font_family='Open Sans, sans-serif', font_color='#FFFFFF')
                            .update_traces(hovertemplate="<b>%{x}</b><extra></extra>")
                        )
            ]


start = 0
parser = argparse.ArgumentParser()
parser.add_argument("-b", "--both", help="import explorer reports and start web app, COMMAND: aggregator.py -b <file.csv> ",
                    action="store_true")
parser.add_argument("-i", "--imp", help="processing explorer reports only, COMMAND: aggregator.py -i <file.csv> ",
                    action="store_true")
parser.add_argument('files', nargs='*') 
parser.add_argument("-w", "--web", help="start dash web app only, COMMAND: aggregator.py -w",
                    action="store_true")
args = parser.parse_args()

if args.both:
    print("\nImporting the reports, web app will be starting after this if there is no error...\n")
elif args.imp:
    print("\nImporting the report and processing...\n")
    start = 1
elif args.web:
    print("\nStarting the dash web app only...\n")
    start = 2

# columns variable
SRC_IPL_COLS = ['consumer_subnet', 'consumer_iplist', 'provider_appgroup_combined', 'provider_app', 'provider_env', 'provider_loc']
DST_IPL_COLS = ['consumer_appgroup_combined', 'consumer_app', 'consumer_env', 'consumer_loc', 'provider_subnet', 'provider_iplist']
common_cols = ['transmission', 'port', 'protocol', 'reported_policy_decision', 'reported_by', 'first_detected', 'last_detected', 'num_flows']

if start != 2:
# init check
    try: 
        if stat(argv[2]).st_size == 0:
            print("File is invalid or 0 byte.")
            exit(1)
        elif 'csv' in argv[2]:
            df = pd.read_csv(argv[2], low_memory=False)
            if df.columns[0] == 'Consumer IP': # first column always this 
                pass
            else:
                print("File is invalid or 0 byte.")
                exit(1)
        else:
            print("File is invalid or 0 byte.")
            exit(1)
    except Exception:
        print("File is invalid or 0 byte.")
        exit(1)

    # Process formatter
    datestr = date.today().strftime("%Y%m%d")
    path = "reports/"
    updated_df, system_or_draft = combine_aggroup_column(csv_formatter(df))

    # Reporting
    df_src_iplist_result, df_dst_iplist_result, df_both_vens_result, df_both_vens_intrascope_result, df_both_vens_extrascope_result = determine_iplist_or_vens_rows(updated_df, system_or_draft)

    reports_output(consumer_as_iplist_result(df_src_iplist_result), provider_as_iplist_result(df_dst_iplist_result), both_vens_result(df_both_vens_intrascope_result), both_vens_result(df_both_vens_extrascope_result))


if start != 1:
    # Start dash web app, App layout
    app = dash.Dash(__name__, prevent_initial_callbacks=True, suppress_callback_exceptions=True)

    # Populate the file upload function on the web
    app_layout = upload_function()

    # Processing dash_table and bar chart
    bar_chart_output(dash_table_output(app_layout))

    # run the dash app
    if __name__ == '__main__':
        app.run_server(debug=True)
            